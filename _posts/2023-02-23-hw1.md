---
layout: post
title: EMIA4110 HW1 
category: EMIA
---
# Practical Machine Learning: Assignment 1

## 1. Simple Linear Regression Problem
Solution:
$$\bar{x}=3.14$$
$$\bar{y}=61$$
$$\alpha=\frac{\sum_{i=1}^n{(x_i-\bar{x})(y_i-\bar{y})}}{\sum_{i=1}^n{(x_i-\bar{x})^2}}=5.88$$
$$\beta=\bar{y}-\alpha\bar{x}=42.5$$

best-fit simple linear model: $$y=5.88x+42.5$$

predicted score when x = 8:
$$5.88*8 + 42.5 = 89.5$$

## 2. Multiple Regression Problem
python code:

    import numpy as np 
    x=np.genfromtxt("q2x.csv")
    y=np.genfromtxt("q2y.csv")
    beta=np.linalg.inv(x.T@x)@x.T@y
    print(beta)

Positive factor:
$$X_2,X_3$$

Expected annual return for a stock with P/E Ratio=20.1, P/B
Ratio = 1.2, ROE = 16%:

    new=np.array([1,20.1,1.2,0.16])
    print(new@beta)

Output: $$0.12041817432496604 \\ = 12\% $$

## 3. Polynomial Regression Problem
the best degree is 4\
python code:

    import numpy as np

    X=np.genfromtxt("q3x.csv")
    Y=np.genfromtxt("q3y.csv")

    X_train = X[:15]
    Y_train = Y[:15]
    X_val = X[15:]
    Y_val = Y[15:]

    def polynomial_regression(X, Y, degree):
        X_poly = np.column_stack([X**i for i in range(degree + 1)])
        coeffs = np.linalg.inv(X_poly.T.dot(X_poly)).dot(X_poly.T).dot(Y)
        return coeffs

    def calculate_SSR(X, Y, coeffs):
        Y_pred = np.polyval(np.flip(coeffs), X)
        SSR = np.sum((Y - Y_pred)**2)
        return SSR

    best_degree = None
    min_SSR = float('inf')

    for degree in range(1, 11): 
        coeffs = polynomial_regression(X_train, Y_train, degree)
        SSR = calculate_SSR(X_val, Y_val, coeffs)
        if SSR < min_SSR:
            min_SSR = SSR
            best_degree = degree

    best_coeffs = polynomial_regression(X, Y, best_degree)

The Resulting Strain for Applied Stress = 76.5 MPa:
$$0.188197902231724$$

python code: 

    applied_stress = 76.5
    resulting_strain = np.polyval(np.flip(best_coeffs), applied_stress)


## 4. Ridge Regression Conversion
$$\beta=\begin{bmatrix} 4.53805820*{10^{-04}} \\ 4.27888282*{10^{-04}} \\ 8.42208702*{10^{-06}} \\ 2.24434850*{10^{-7}} \\
 1.53110383*{10^{-10}}\end{bmatrix}$$

 python code: 

    import numpy as np

    X=np.genfromtxt("q3x.csv")
    Y=np.genfromtxt("q3y.csv")
    lam=0.01

    X_poly = np.column_stack([X**i for i in range(4 + 1)])
    I = np.identity(X_poly.shape[1])
    coeffs = np.linalg.inv(X_poly.T.dot(X_poly)+lam*I).dot(X_poly.T).dot(Y)

    print(coeffs)

## 5. Classification Performance Metrics
| Prediction \Ground Truth |  P | N  |
|---|---|---|
| P  |  7   | 2  |
| N  |   3 | 8  |

|||
|---|---|
|TP|FP|
|FN|TN|

$$Accuracy=\frac{TP+TN}{TP+TN+FP+FN}=\frac{7+8}{7+8+2+3}=3/4=0.75$$

$$Recall=\frac{TP}{FN+TP}=\frac{7}{7+3}=7/10=0.7$$

$$Precision=\frac{TP}{TP+FP}=\frac{7}{7+2}=7/9=0.77777777777$$

$$F1=\frac{2*Precision*Recall}{Precision+Recall}=\frac{2*{7/9}*{7/10}}{{7/9}+{7/10}}=\frac{98}{133}=0.73684210526$$

## 6. Naive Bayes Classifier
The class for the sample (-5.7,-4.3,-3.34) is 3

pyhton code:

    import numpy as np

    X=np.genfromtxt("q6x.csv")
    y=np.genfromtxt("q6y.csv")

    def estimate_gaussian_parameters(data):
        mean = np.mean(data, axis=0)
        std_dev = np.std(data, axis=0)
        return mean, std_dev

    def compute_prior_probabilities(labels):
        unique_labels, counts = np.unique(labels, return_counts=True)
        prior_probs = counts / len(labels)
        return prior_probs

    def compute_likelihood(test_sample, class_means, class_std_devs):
        likelihoods = np.zeros(shape=(3,3))
        for i in range(len(class_means)):
            likelihood = np.exp(-0.5 * ((test_sample - class_means[i]) / class_std_devs[i]) ** 2) / (np.sqrt(2 * np.pi) * class_std_devs[i])
            likelihoods[i,:]+=likelihood

        return likelihoods.T

    def compute_posterior(likelihoods, prior_probs):
        return likelihoods[0,:]*likelihoods[1,:]*likelihoods[2,:]*prior_probs

    class_means = []
    class_std_devs = []
    for i in range(int(max(y))):
        class_data = X[y == (i+1)]
        class_mean, class_std_dev = estimate_gaussian_parameters(class_data)
        class_means.append(class_mean)
        class_std_devs.append(class_std_dev)

    prior_probs = compute_prior_probabilities(y)

    test_sample = np.array([-5.7, -4.3, -3.34])

    likelihoods = compute_likelihood(test_sample, class_means, class_std_devs)

    posteriors = compute_posterior(likelihoods, prior_probs)

    predicted_class = np.argmax(posteriors)+1

    print(posteriors)
    print(predicted_class)


